{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import change_detection_pytorch as cdp\n",
    "from change_detection_pytorch.datasets import LEVIR_CD_Dataset, SVCD_Dataset\n",
    "from change_detection_pytorch.utils.lr_scheduler import GradualWarmupScheduler\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = cdp.Unet(\n",
    "    encoder_name=\"resnet34\",  # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",  # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=2,  # model output channels (number of classes in your datasets)\n",
    "    siam_encoder=True,  # whether to use a siamese encoder\n",
    "    fusion_form='concat',  # the form of fusing features from two branches. e.g. concat, sum, diff, or abs_diff.\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 80 images\n",
      "Loaded 63 images\n"
     ]
    }
   ],
   "source": [
    "train_dataset = LEVIR_CD_Dataset('D:/Omkar/COEP TY/TY Sem VI/Research AI/Code/LEVIR-CD/train',\n",
    "                                 sub_dir_1='A',\n",
    "                                 sub_dir_2='B',\n",
    "                                 img_suffix='.png',\n",
    "                                 ann_dir='D:/Omkar/COEP TY/TY Sem VI/Research AI/Code/LEVIR-CD/train/label',\n",
    "                                 debug=False)\n",
    "\n",
    "valid_dataset = LEVIR_CD_Dataset('D:/Omkar/COEP TY/TY Sem VI/Research AI/Code/LEVIR-CD/test',\n",
    "                                 sub_dir_1='A',\n",
    "                                 sub_dir_2='B',\n",
    "                                 img_suffix='.png',\n",
    "                                 ann_dir='D:/Omkar/COEP TY/TY Sem VI/Research AI/Code/LEVIR-CD/test/label',\n",
    "                                 debug=False,\n",
    "                                 test_mode=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = cdp.utils.losses.CrossEntropyLoss()\n",
    "metrics = [\n",
    "    cdp.utils.metrics.Fscore(activation='argmax2d'),\n",
    "    cdp.utils.metrics.Precision(activation='argmax2d'),\n",
    "    cdp.utils.metrics.Recall(activation='argmax2d'),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([\n",
    "    dict(params=model.parameters(), lr=0.0001),\n",
    "])\n",
    "\n",
    "scheduler_steplr = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50, ], gamma=0.1)\n",
    "\n",
    "# create epoch runners\n",
    "# it is a simple loop of iterating over dataloader`s samples\n",
    "train_epoch = cdp.utils.train.TrainEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = cdp.utils.train.ValidEpoch(\n",
    "    model,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train: 100%|██████████| 10/10 [00:46<00:00,  4.67s/it, cross_entropy_loss - 0.7583, fscore - 0.1173, precision - 0.06759, recall - 0.5327] \n",
      "valid: 100%|██████████| 63/63 [02:54<00:00,  2.77s/it, cross_entropy_loss - 0.665, fscore - 0.07041, precision - 0.04424, recall - 0.4743] \n",
      "max_score 0.0704096848254255\n",
      "Model saved!\n",
      "\n",
      "Epoch: 1\n",
      "train: 100%|██████████| 10/10 [00:45<00:00,  4.59s/it, cross_entropy_loss - 0.6545, fscore - 0.1508, precision - 0.08906, recall - 0.5964]\n",
      "valid: 100%|██████████| 63/63 [02:54<00:00,  2.77s/it, cross_entropy_loss - 0.7798, fscore - 0.09932, precision - 0.0587, recall - 0.7309] \n",
      "max_score 0.09931573714869657\n",
      "Model saved!\n",
      "\n",
      "Epoch: 2\n",
      "train: 100%|██████████| 10/10 [00:46<00:00,  4.62s/it, cross_entropy_loss - 0.5454, fscore - 0.2576, precision - 0.1725, recall - 0.625]  \n",
      "valid: 100%|██████████| 63/63 [02:52<00:00,  2.74s/it, cross_entropy_loss - 0.5769, fscore - 0.1262, precision - 0.07928, recall - 0.5959]\n",
      "max_score 0.12618438586953473\n",
      "Model saved!\n",
      "valid: 100%|██████████| 63/63 [02:58<00:00,  2.83s/it]\n"
     ]
    }
   ],
   "source": [
    "# train model for 60 epochs\n",
    "\n",
    "max_score = 0\n",
    "MAX_EPOCH = 3\n",
    "\n",
    "for i in range(MAX_EPOCH):\n",
    "\n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(valid_loader)\n",
    "    scheduler_steplr.step()\n",
    "\n",
    "    # do something (save model, change lr, etc.)\n",
    "    if max_score < valid_logs['fscore']:\n",
    "        max_score = valid_logs['fscore']\n",
    "        print('max_score', max_score)\n",
    "        torch.save(model, './best_model.pth')\n",
    "        print('Model saved!')\n",
    "\n",
    "# save results (change maps)\n",
    "\"\"\"\n",
    "Note: if you use sliding window inference, set: \n",
    "    from change_detection_pytorch.datasets.transforms.albu import (\n",
    "        ChunkImage, ToTensorTest)\n",
    "    \n",
    "    test_transform = A.Compose([\n",
    "        A.Normalize(),\n",
    "        ChunkImage({window_size}}),\n",
    "        ToTensorTest(),\n",
    "    ], additional_targets={'image_2': 'image'})\n",
    "\n",
    "\"\"\"\n",
    "valid_epoch.infer_vis(valid_loader, save=True, slide=False, save_dir='./res')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
